{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxfilter and time-domain band-pass filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Using the upgraded 2016-versions of `stormdb`-functionality.)\n",
    "\n",
    "Running `maxfilter` and band-pass filtering (using `mne-python`'s raw-data method `raw.filter`) can be off-loaded to the cluster for load-balanced processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General\n",
    "\n",
    "### On the naming logic for the study\n",
    "\n",
    "There are only two blocks (`equi` and `opt`). Data will never be compared at the sensor level between the two blocks, so each can be head motion compensated to its initial head position (basic `maxfilter` usage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a development version of `mne-python` and `stormdb-python`\n",
    "\n",
    "__NB:__ The following only needs to be run once, on the command line of any interactive server.\n",
    "\n",
    "This way the version of the analysis code can be kept with the scripts using them, for future reproduction of results. To get the code, and to make a \"snapshot\" of the state of the code (in case you modify anything accidentally), open a terminal in a remote desktop and (suggestion):\n",
    "\n",
    "```bash\n",
    "cd /projects/MINDLAB2016_MEG-Language-PD-DBS/misc\n",
    "git clone https://github.com/mne-tools/mne-python.git\n",
    "cd mne-python\n",
    "git checkout -b snapshot_20160803\n",
    "\n",
    "cd /projects/MINDLAB2016_MEG-Language-PD-DBS/misc\n",
    "git clone https://github.com/meeg-cfin/stormdb-python.git\n",
    "cd stormdb-python\n",
    "git fetch origing refactor_submit:refactor_submit\n",
    "git checkout -b refactor_submit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output file and folder names\n",
    "\n",
    "Remember to use the project `scratch` folder for output, and make it easy to clean up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "proj_name = 'MINDLAB2016_MEG-Language-PD-DBS'\n",
    "scratch_folder = join('/projects', proj_name, 'scratch')\n",
    "mf_folder = join(scratch_folder, 'maxfilter')  # for maxfilter output\n",
    "scripts_folder = join('/projects', proj_name, 'scripts')\n",
    "misc_folder = join('/projects', proj_name, 'misc')\n",
    "trans_folder = join(scratch_folder, 'trans')  # for transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify path by adding the mne-python folder from scripts to the beginning.\n",
    "import sys\n",
    "sys.path = [join(misc_folder, 'mne-python'),\n",
    "            join(misc_folder, 'stormdb-python')] + sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "In Python, we have to load what we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stormdb.access import Query\n",
    "from stormdb.process import Maxfilter\n",
    "from mne.io import Raw\n",
    "from mne.bem import fit_sphere_to_headshape\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# silence mne a bit\n",
    "from mne.utils import set_log_level\n",
    "set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant parameters\n",
    "\n",
    "Place parameters here you might want to play with, such as tSSS buffer length and correlation limit. Output folders will be automatically generated to reflect these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsss_buffer_len = 16\n",
    "tsss_corr_lim = 0.96\n",
    "# if you know that some channels are bad or flat, enter them here\n",
    "# in the form ['2511', '2241']\n",
    "static_bad_chans = ['2511'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the data\n",
    "\n",
    "Instead of accessing raw files directly, use the database query functions to get to files.\n",
    "\n",
    "Note that `get_subjects` by default only returns a list of non-excluded subjects, this may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qr = Query(proj_name)\n",
    "subs = qr.get_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the subjects in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0001_JNC\n",
      "1: 0002_FYX\n"
     ]
    }
   ],
   "source": [
    "for ii, ss in enumerate(subs):\n",
    "    print('{0}: {1}'.format(ii, ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select subject\n",
    "\n",
    "Instead of writing a script that loops over subjects (could be done), this notebook requires you to select one subject at a time. The advantage is that you then sanity-check each stage before continuing. The final `submit_to_cluster` commands do not block the notebook: you can immediately go forward with the next subject. New submissions will simply be added to the queue.\n",
    "\n",
    "To make this semi-automatic, the variable `cur_sub_index` will be incremented by 1 every time the `submit`-command is issued at the end of this notebook. You can also just manually set the index to what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current subject: 0002_FYX\n"
     ]
    }
   ],
   "source": [
    "cur_sub_index = 1  # see below for the meaning of this\n",
    "cur_sub = subs[cur_sub_index]\n",
    "print('Current subject: {sub:s}'.format(sub=cur_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_specific_bad_chans = []  # empty list if no (more) bad chans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternatively, just state the ID of the subject\n",
    "# cur_sub = '0008'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the head positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to calculate the average initial head position and use movecomp to correct head motion to that origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: /projects/MINDLAB2016_MEG-Language-PD-DBS/raw/0002/20160802_000000/MEG/001.optimum/files\n",
      "2: /projects/MINDLAB2016_MEG-Language-PD-DBS/raw/0002/20160802_000000/MEG/002.equi/files\n"
     ]
    }
   ],
   "source": [
    "description = '*equi|*optim*'\n",
    "DATAblocks = qr.filter_series(description=description, subjects=cur_sub,\n",
    "                              modalities='MEG')\n",
    "\n",
    "if len(DATAblocks) != 2:\n",
    "    raise RuntimeError('Not all 2 blocks found for {0}, please check!'.\\\n",
    "                       format(cur_sub))\n",
    "for ib in range(len(DATAblocks)):\n",
    "    print('{:d}: {:s}'.format(ib + 1, DATAblocks[ib]['path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit head origin for SSS expansion\n",
    "\n",
    "Any info will do, since the digitization points are the same for all blocks. We'll take the first one. NB: Only use EEG locations, since head points only on face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted sphere radius:         87.9 mm\n",
      "Origin head coordinates:      2.4 2.6 42.9 mm\n",
      "Origin device coordinates:    0.2 9.4 -7.8 mm\n"
     ]
    }
   ],
   "source": [
    "info = Raw(os.path.join(DATAblocks[0]['path'], DATAblocks[0]['files'][0]),\n",
    "           preload=False).info\n",
    "set_log_level('INFO')\n",
    "rad, origin_head, ori_dev = fit_sphere_to_headshape(info,\n",
    "                                                    dig_kinds='eeg',\n",
    "                                                    units='mm')\n",
    "set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Maxfilter-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mf = Maxfilter(proj_name, bad=static_bad_chans + sub_specific_bad_chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build maxfilter commands for all the blocks\n",
    "\n",
    "First set some of the options (leave others as default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfopts = dict(\n",
    "    origin = '{:.1f} {:.1f} {:.1f}'.format(*tuple(origin_head)),  # mm\n",
    "    frame = 'head',\n",
    "    force = True,  # overwrite if needed\n",
    "    autobad = 'on',  # or use xscan first\n",
    "    st = True,  # use tSSS\n",
    "    st_buflen = tsss_buffer_len,  # parameter set in beg. of notebook\n",
    "    st_corr = tsss_corr_lim,  # parameter set in beg. of notebook\n",
    "    movecomp = True,\n",
    "    trans = None,  # compensate to mean initial head position (saved to file),\n",
    "                              # or use None for initial head position\n",
    "    logfile = None,  # we replace this in each loop\n",
    "    hp = None,  # head positions, replace in each loop\n",
    "    n_threads = 4  # number of parallel threads to run on\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mne-python likes raw and raw-like (tsss) files that are part of a long (>2GB) continuous acquisition to follow the convention:\n",
    "\n",
    "1. `filename_raw_tsss.fif` (first file)\n",
    "1. `filename_raw_tsss-1.fif` (second file, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: /projects/MINDLAB2016_MEG-Language-PD-DBS/scratch/maxfilter/tsss_st16_corr96/0002_FYX\n"
     ]
    }
   ],
   "source": [
    "out_folder = join(mf_folder,\n",
    "                  'tsss_st{:d}_corr{:.0f}'.\\\n",
    "                      format(mfopts['st_buflen'],\n",
    "                             np.round(100 * mfopts['st_corr'])),\n",
    "                  cur_sub)\n",
    "\n",
    "# Ensure that output path exists\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "print('Output folder: {:s}'.format(out_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for each block, loop over the associated files (a single file if the data size is less than 2 GB), and:\n",
    "* define input file name\n",
    "* determine the name of the block (\"series\")\n",
    "* define the output file path by combining the output path with a name based on the block name, suffixed by \"`_raw_tsss.fif`\"\n",
    "    * if multiple-file acquisition, add the Elekta-standard suffixes\n",
    "* define the output log- and head position-file names\n",
    "* build the `maxfilter`-command based on all the definitions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for blockno, bl in enumerate(DATAblocks):\n",
    "    for fileno, fil in enumerate(bl['files']):\n",
    "        in_fname = join(bl['path'], bl['files'][fileno])\n",
    "        \n",
    "        series_name = re.search('(equi|optimum)',\n",
    "                                bl['seriename']).group(1)\n",
    "        \n",
    "        out_fname = join(out_folder, '{:s}_raw_tsss.fif'.format(series_name))\n",
    "        if fileno > 0:  # data size > 2 GB\n",
    "            out_fname = out_fname[:-4] + '-{:d}.fif'.format(fileno)\n",
    "           \n",
    "        mfopts['logfile'] = out_fname[:-3] + 'log'\n",
    "        mfopts['hp'] = out_fname[:-3] + 'pos'\n",
    "        \n",
    "        mf.build_cmd(in_fname, out_fname, **mfopts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to isis for processing\n",
    "\n",
    "We need to use the `isis.q`, since at present that is the only queue where `maxfilter` is available.\n",
    "\n",
    "First check that you think sane things will happen, if you like.\n",
    "\n",
    "To comment out a line in python, prefix the line with a '# '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All inputs readable & outputs writable.\n",
      "/projects/MINDLAB2016_MEG-Language-PD-DBS/raw/0002/20160802_000000/MEG/001.optimum/files/PROJ0252_SUBJ0002_SER001_FILESNO001.fif\n",
      "\t--> /projects/MINDLAB2016_MEG-Language-PD-DBS/scratch/maxfilter/tsss_st16_corr96/0002_FYX/optimum_raw_tsss.fif\n",
      "/projects/MINDLAB2016_MEG-Language-PD-DBS/raw/0002/20160802_000000/MEG/002.equi/files/PROJ0252_SUBJ0002_SER002_FILESNO001.fif\n",
      "\t--> /projects/MINDLAB2016_MEG-Language-PD-DBS/scratch/maxfilter/tsss_st16_corr96/0002_FYX/equi_raw_tsss.fif\n"
     ]
    }
   ],
   "source": [
    "# This is not executed, but the line below is\n",
    "mf.check_input_output_mapping()\n",
    "mf.print_input_output_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in doubt, uncomment this line to see the actual commands that will execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mf.commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster job submitted, job ID: 3550337\n",
      "Cluster job submitted, job ID: 3550338\n"
     ]
    }
   ],
   "source": [
    "mf.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking what's going on\n",
    "\n",
    "In a terminal:\n",
    "\n",
    "```bash\n",
    "qstat\n",
    "```\n",
    "\n",
    "shows all _your_ running jobs. For _every/anyone's_ jobs, run\n",
    "\n",
    "```bash\n",
    "qstat -u \"*\"\n",
    "```\n",
    "\n",
    "You can also just \"ask\" the `mf`-object what its status is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 (3550337): Running on isis (isis.q)\n",
      "#2 (3550338): Running on isis (isis.q)\n"
     ]
    }
   ],
   "source": [
    "mf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill a submitted (or even running) job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mf.kill(3550319)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill all submitted jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mf.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill a job in the shell:\n",
    "\n",
    "```\n",
    "qdel JOB_NUMBER\n",
    "```\n",
    "\n",
    "or for all jobs (in your name):\n",
    "\n",
    "```\n",
    "qdel *\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Band-pass filter the maxfiltered data\n",
    "\n",
    "Use the information in the input-output mapping of the previous analysis stage to feed into the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': u'/projects/MINDLAB2016_MEG-Language-PD-DBS/raw/0002/20160802_000000/MEG/001.optimum/files/PROJ0252_SUBJ0002_SER001_FILESNO001.fif',\n",
       "  'output': u'/projects/MINDLAB2016_MEG-Language-PD-DBS/scratch/maxfilter/tsss_st16_corr96/0002_FYX/optimum_raw_tsss.fif'},\n",
       " {'input': u'/projects/MINDLAB2016_MEG-Language-PD-DBS/raw/0002/20160802_000000/MEG/002.equi/files/PROJ0252_SUBJ0002_SER002_FILESNO001.fif',\n",
       "  'output': u'/projects/MINDLAB2016_MEG-Language-PD-DBS/scratch/maxfilter/tsss_st16_corr96/0002_FYX/equi_raw_tsss.fif'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.info['io_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stormdb.process import MNEPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnep = MNEPython(proj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_freq = 1.\n",
    "h_freq = 40.\n",
    "filter_folder = join(scratch_folder, 'filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: /projects/MINDLAB2016_MEG-Language-PD-DBS/scratch/filtered/1-40/0002_FYX\n"
     ]
    }
   ],
   "source": [
    "out_folder = join(filter_folder,\n",
    "                  '{0:.0f}-{1:.0f}'.format(l_freq or 'None',\n",
    "                                   h_freq or None), cur_sub)\n",
    "\n",
    "# Ensure that output path exists\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "print('Output folder: {:s}'.format(out_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for curmap in mf.info['io_mapping']:\n",
    "    in_fname = curmap['output']\n",
    "    out_fname = join(out_folder, basename(curmap['output'])[:-4] + '_filt_raw.fif')\n",
    "    mnep.raw_filter(in_fname, out_fname, l_freq, h_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster job submitted, job ID: 3550332\n",
      "Cluster job submitted, job ID: 3550333\n"
     ]
    }
   ],
   "source": [
    "mnep.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 (3550332): Job completed\n",
      "#2 (3550333): Job completed\n"
     ]
    }
   ],
   "source": [
    "mnep.status"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
